# Diffusion-Based Point Cloud Completion for Cultural Artifact Restoration

**Author**: Nguyen Dinh Hieu, Phan Duy Hung  
**Affiliation**: FPT University  
**Contact**: hieundhe180318@fpt.edu.vn, hungpd2@fe.edu.vn

---

## ‚ú® Abstract

Digital restoration of ancient artifacts‚Äîespecially those with intricate and irregular geometries‚Äîposes significant challenges. This project proposes a method leveraging **conditional diffusion models** to perform high-fidelity 3D shape completion from partial point clouds. By training on both general and culturally specific datasets (e.g., Precolumbian Pottery), our model learns detailed geometric priors and enables robust reconstruction. We report strong performance using metrics like Chamfer Distance and Hausdorff Distance, highlighting its relevance in AI-assisted cultural heritage preservation.

---
## üîß Dependencies

| **Framework / Library** | **Version** |
|:------------------------|:------------|
| [![PyTorch](https://img.shields.io/badge/PyTorch-2.2.1-red?logo=pytorch&logoColor=white)](https://pytorch.org) | 2.2.1+cu118 |
| [![TorchVision](https://img.shields.io/badge/TorchVision-0.17.1-yellow?logo=pytorch&logoColor=white)](https://pytorch.org/vision/stable/index.html) | 0.17.1+cu118 |
| [![Python](https://img.shields.io/badge/Python-3.12-blue?logo=python&logoColor=white)](https://python.org) | 3.12 |
| [![matplotlib](https://img.shields.io/badge/matplotlib-latest-orange?logo=plotly&logoColor=white)](https://matplotlib.org) | latest |
| [![tqdm](https://img.shields.io/badge/tqdm-latest-brightgreen)](https://tqdm.github.io) | latest |
| [![trimesh](https://img.shields.io/badge/trimesh-latest-lightgrey)](https://trimsh.org) | latest |
| [![ninja](https://img.shields.io/badge/ninja-build-blue)](https://ninja-build.org) | latest |
| [![pynrrd](https://img.shields.io/badge/pynrrd-latest-blueviolet)](https://github.com/mhe/pynrrd) | latest |
| [![open3d](https://img.shields.io/badge/open3d-0.17-green?logo=open3d)](http://www.open3d.org) | 0.17 |
| [![PyMCubes](https://img.shields.io/badge/PyMCubes-latest-lightblue)](https://github.com/pmneila/PyMCubes) | latest |

---

## üì¶ Pretrained Checkpoint & Processed Dataset

- üîó **Trained Model Checkpoint**:  
  [üì• Download epoch_14999.pth](https://drive.google.com/file/d/1yQR6Eyp5iXwPyy7uAE8hCubfEDYKp2k5/view?usp=sharing)  
  *(stored under `experiments/train_completion/2025-05-10-20-14-58/checkpoints/`)*

- üìÇ **Processed Dataset (Precol)**:  
  [üì• Download precol](https://drive.google.com/drive/folders/1J_Fj85E_47LArfw800S6IO5SkGYdQdqU?usp=sharing)  
  *(includes train/test CSVs and ready-to-use `.ply` files)*

> Replace `https://your-cloud-link/...` with your actual cloud storage URL (Google Drive, HuggingFace, etc.).
## üìÇ Table of Contents
- [üõ†Ô∏è Environment Setup](#environment-setup)
- [üìÅ Dataset Preparation](#dataset-preparation)
- [üöÄ Training](#training)
- [üß™ Evaluation](#evaluation)
- [üëÄ Visualization](#visualization)
- [üìê Model Architecture](#model-architecture)
- [üìä Metrics](#metrics)
- [üìé Project Structure](#project-structure)

---

## üõ†Ô∏è Environment Setup

### Requirements
- Python >= 3.10
- PyTorch (CUDA-enabled)
- NVIDIA GPU with CUDA toolkit (recommended: RTX 4090+ 48GB)
- g++, nvcc for custom extensions

### Installation
```bash
cd /workspace/pcdiff-method
python3 -m venv env
source env/bin/activate
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
```

If custom CUDA ops are used (e.g., in `pvcnn_completion.py`):
```bash
pip install -e .
```

---

## üìÅ Dataset Preparation

Supports CSV-formatted datasets.

- Format (`precol/train.csv`):
```csv
/path/to/fragmented_object1.ply
/path/to/fragmented_object2.ply
```

Organize files under `data/precol/raw` and update CSVs accordingly.

---

## üöÄ Training

Train on `precol` dataset:
```bash
python -m pcdiff.train_completion --path data/precol/train.csv --dataset precol --bs 8 --output_dir experiments/train_completion/$(date +%Y-%m-%d-%H-%M-%S)
```

- Batch size: 8
- Optimizer: Adam (LR=1e-4)
- 1000 diffusion steps
- Epochs: 500 (Geometric), 4000 (Precolumbian)

---

## üß™ Evaluation

Run inference on test set:
```bash
python -m pcdiff.test_completion --path data/precol/test.csv --dataset precol --model experiments/train_completion/<RUN_ID>/checkpoints/epoch_14999.pth --eval_path results/precol_test/<RUN_ID> --bs 8
```

Outputs:
- `input.npy`, `sample.npy`, `.ply` files
- `metrics.json`

---

## üëÄ Visualization

To visualize `.npy` or export `.ply`:
```bash
python scripts/visualize_npy_pointcloud.py results/precol_test/<RUN_ID>/syn/<sample>/sample.npy
```

Use MeshLab or CloudCompare for `.ply`.

---

## üìê Model Architecture

- **Encoder**: PointNet++
- **Decoder**: Feature propagation + MLP
- **Diffusion**: Conditional on partial input (`c_0`), denoises `~x_0` over 1000 steps

---

## üìä Metrics

- **Chamfer Distance Factor (CDF)**
- **Hausdorff Distance Factor (HDF)**

Evaluate closeness to ground truth, normalized by object scale.

---

## üìé Project Structure
```
/workspace/pcdiff-method/
‚îú‚îÄ‚îÄ pcdiff/                     # This seems to be your main Python package for the core logic.
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py             # Makes 'pcdiff' a Python package.
‚îÇ   ‚îú‚îÄ‚îÄ model/                  # Where your neural network model definitions live.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pvcnn_completion.py # For example, your PVCNN2Base model.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                 # Other model-related files.
‚îÇ   ‚îú‚îÄ‚îÄ datasets/               # Code for loading and handling your datasets.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ precol_dataset.py   # A custom dataset class for 'precol'.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                 # Other dataset handlers.
‚îÇ   ‚îú‚îÄ‚îÄ utils/                  # Helper functions and utility scripts.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ file_utils.py       # For file operations.
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ visualize.py        # For visualization tasks.
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...                 # Other general utilities.
‚îÇ   ‚îú‚îÄ‚îÄ train_completion.py     # The script you use to train your completion models.
‚îÇ   ‚îú‚îÄ‚îÄ test_completion.py      # The script for evaluating your trained models.
‚îÇ   ‚îî‚îÄ‚îÄ diffusion.py            # Core diffusion model logic (like GaussianDiffusion).
‚îÇ
‚îú‚îÄ‚îÄ data/                       # A general place to store raw and processed datasets.
‚îÇ   ‚îî‚îÄ‚îÄ precol/                 # Specific to your 'precol' dataset.
‚îÇ       ‚îú‚îÄ‚îÄ train.csv           # CSV file listing paths/info for training samples.
‚îÇ       ‚îú‚îÄ‚îÄ test.csv            # CSV file listing paths/info for test samples.
‚îÇ       ‚îî‚îÄ‚îÄ raw/                # (Optional) Original raw data files (e.g., .ply, .obj).
‚îÇ       ‚îî‚îÄ‚îÄ processed/          # (Optional) Data after any preprocessing steps.
‚îÇ
‚îú‚îÄ‚îÄ experiments/                # To store outputs from training runs.
‚îÇ   ‚îî‚îÄ‚îÄ train_completion/       # Specific to completion training.
‚îÇ       ‚îî‚îÄ‚îÄ 2025-05-10-20-14-58/ # A unique ID for each training run (timestamp is good!).
‚îÇ           ‚îú‚îÄ‚îÄ checkpoints/    # Where model checkpoints like .pth files are saved.
‚îÇ           ‚îÇ   ‚îú‚îÄ‚îÄ epoch_00000.pth
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ epoch_14999.pth
‚îÇ           ‚îú‚îÄ‚îÄ logs/           # Training logs, tensorboard events, etc.
‚îÇ           ‚îÇ   ‚îî‚îÄ‚îÄ training_log.txt
‚îÇ           ‚îî‚îÄ‚îÄ config.yaml     # (Optional but good) The configuration used for this run.
‚îÇ
‚îú‚îÄ‚îÄ results/                    # For outputs from your testing/evaluation runs.
‚îÇ   ‚îî‚îÄ‚îÄ precol_test/            # Results for the 'precol' test set.
‚îÇ       ‚îî‚îÄ‚îÄ 2025-05-10-20-14-58_epoch_14999/ # ID for which model was tested.
‚îÇ           ‚îî‚îÄ‚îÄ syn/            # Synthesized/completed outputs.
‚îÇ               ‚îî‚îÄ‚îÄ NA-native_10_0/ # Output for a specific sample.
‚îÇ                   ‚îú‚îÄ‚îÄ input.npy
‚îÇ                   ‚îú‚îÄ‚îÄ sample.npy
‚îÇ                   ‚îú‚îÄ‚îÄ input.ply   # (If you save .ply files too)
‚îÇ                   ‚îî‚îÄ‚îÄ sample.ply
‚îÇ           ‚îî‚îÄ‚îÄ metrics.json    # (Optional) Quantitative evaluation metrics.
‚îÇ
‚îú‚îÄ‚îÄ scripts/                    # Any standalone helper scripts.
‚îÇ   ‚îú‚îÄ‚îÄ download_dataset.sh     # Script to download data, if applicable.
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_data.py      # Script for any data preprocessing steps.
‚îÇ   ‚îî‚îÄ‚îÄ visualize_npy_pointcloud.py # Your script for viewing .npy outputs.
‚îÇ
‚îú‚îÄ‚îÄ env/                        # Your Python virtual environment (e.g., if using venv).
‚îÇ
‚îú‚îÄ‚îÄ .gitignore                  # Tells Git which files/directories to ignore (like env/, __pycache__/, *.pyc, large data files if not tracked).
‚îú‚îÄ‚îÄ requirements.txt
```
---

> For cultural institutions, museums, and digital archaeologists: this project represents a novel, AI-augmented framework to support the digital preservation of humanity‚Äôs most intricate historical artifacts.
